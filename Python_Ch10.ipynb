{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNgC4XXQmtfUIqRUm6kWoBn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrahmani/Python/blob/main/Python_Ch10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct a PyTorch Multi-Layer Perceptron (MLP) with 2 inputs, a hidden layer of 4 neurons, and a single output, then train it using backpropagation to predict the product of two integer inputs. Train the model on 20 input-output pairs (with inputs ranging from 1 to 6) and test it on 2 new cases."
      ],
      "metadata": {
        "id": "hFKFZZRDcWZ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5en7Ugb_vk_3",
        "outputId": "4a563d03-53c7-4933-ee22-6e3cf7c6507c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch [100/1000], Loss: 7.59\n",
            "Epoch [200/1000], Loss: 6.47\n",
            "Epoch [300/1000], Loss: 5.28\n",
            "Epoch [400/1000], Loss: 4.13\n",
            "Epoch [500/1000], Loss: 3.26\n",
            "Epoch [600/1000], Loss: 2.78\n",
            "Epoch [700/1000], Loss: 2.48\n",
            "Epoch [800/1000], Loss: 2.39\n",
            "Epoch [900/1000], Loss: 2.36\n",
            "Epoch [1000/1000], Loss: 2.35\n",
            "Training finished.\n",
            "\n",
            "Testing the model on new cases:\n",
            "Input: 2 x 3 = 6, Predicted: 5.44\n",
            "Input: 6 x 3 = 18, Predicted: 17.66\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 1. Define the MLP architecture\n",
        "class ProductMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ProductMLP, self).__init__()\n",
        "        self.hidden = nn.Linear(2, 4)  # 2 inputs, 4 hidden neurons\n",
        "        self.output = nn.Linear(4, 1)  # 4 hidden neurons, 1 output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden(x)\n",
        "        x = torch.relu(x)  # Apply ReLU activation to hidden layer\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# 2. Generate training data\n",
        "# 20 input-output pairs (inputs ranging from 1 to 6)\n",
        "# You can change these lists to test different training data\n",
        "input_pairs_list = [\n",
        "    [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6],\n",
        "    [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6],\n",
        "    [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [3, 6],\n",
        "    [4, 1], [4, 2] # Only 20 pairs needed\n",
        "]\n",
        "\n",
        "output_products_list = [\n",
        "    1, 2, 3, 4, 5, 6,\n",
        "    2, 4, 6, 8, 10, 12,\n",
        "    3, 6, 9, 12, 15, 18,\n",
        "    4, 8 # Only 20 pairs needed\n",
        "]\n",
        "\n",
        "\n",
        "# Convert lists to PyTorch tensors\n",
        "X_train = torch.tensor(input_pairs_list, dtype=torch.float32)\n",
        "y_train = torch.tensor(output_products_list, dtype=torch.float32).view(-1, 1) # Reshape for compatibility with output layer\n",
        "\n",
        "# Instantiate the model\n",
        "model = ProductMLP()\n",
        "\n",
        "# 3. Define loss function and optimizer\n",
        "criterion = nn.MSELoss() # Mean Squared Error Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01) # Adam optimizer with a learning rate of 0.01\n",
        "\n",
        "# 4. Train the model\n",
        "num_epochs = 1000 # Number of training iterations\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad() # Clear gradients\n",
        "    loss.backward()       # Compute gradients\n",
        "    optimizer.step()      # Update weights\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.2f}')\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "# 5. Test the model on two new cases\n",
        "# You can change these lists to test different cases\n",
        "new_input_pairs = [\n",
        "    [2, 3], # Expected output: 6\n",
        "    [6, 3]  # Expected output: 18\n",
        "]\n",
        "\n",
        "X_test = torch.tensor(new_input_pairs, dtype=torch.float32)\n",
        "\n",
        "print(\"\\nTesting the model on new cases:\")\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad(): # Disable gradient calculation during testing\n",
        "    test_predictions = model(X_test)\n",
        "    for i in range(len(new_input_pairs)):\n",
        "        input_pair = new_input_pairs[i]\n",
        "        prediction = test_predictions[i]\n",
        "        expected_output = input_pair[0] * input_pair[1]\n",
        "        print(f\"Input: {input_pair[0]} x {input_pair[1]} = {expected_output}, Predicted: {prediction.item():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct a PyTorch Multi-Layer Perceptron (MLP) with 2 inputs, a hidden layer of 4 neurons, and a single output, then train it using backpropagation to predict the subtraction of two integer inputs. Train the model on 20 input-output pairs (with inputs ranging from 1 to 6) and test it on 10 new cases."
      ],
      "metadata": {
        "id": "SfSoCMWFccKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the multi-layer perceptron model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        # Define the hidden layer with 3 neurons and input size 2\n",
        "        self.hidden = nn.Linear(2, 3)\n",
        "        # Define the output layer with 1 neuron\n",
        "        self.output = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply LeakyReLU activation function to the hidden layer output\n",
        "        # LeakyReLU helps prevent \"dying ReLUs\" by allowing a small gradient for negative inputs\n",
        "        x = nn.functional.leaky_relu(self.hidden(x)) # Using nn.functional for LeakyReLU\n",
        "        # The output layer directly outputs the result without an activation (for regression)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# Corrected Dataset for Subtruction Prediction\n",
        "dataset_list = [\n",
        "    ((1, 1), 1 - 1), ((1, -2), 1 + 2), ((4, 3), 4 - 3), ((1, 4), 1 - 4),\n",
        "    ((4, 4), 4 - 4), ((-1, 4), -1 - 4), ((3, 1), 3 - 1), ((-2, 2), -2 - 2),\n",
        "    ((3, 3), 3 - 3), ((4, 4), 4 - 4), ((3, 4), 3 - 4), ((3, 2), 3 - 2),\n",
        "    ((5, 1), 5 - 1), ((2, 2), 2 - 2), ((5, -3), 5 + 3), ((2, 4), 2 - 4),\n",
        "    ((5, 5), 5 - 5), ((5, 4), 5 - 4), ((2, 1), 2 - 1), ((6, 2), 6 - 2),\n",
        "    ((-2, 3), -2 - 3), ((6, 4), 6 - 4), ((2, 2), 2 - 2), ((2, 6), 2 - 6)\n",
        "]\n",
        "\n",
        "\n",
        "# Convert data into torch tensors\n",
        "inputs = torch.tensor([data[0] for data in dataset_list], dtype=torch.float32)\n",
        "targets = torch.tensor([data[1] for data in dataset_list], dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "\n",
        "# Model, Loss function, and Optimizer\n",
        "model = MLP()\n",
        "criterion = nn.MSELoss()\n",
        "# **Crucial Change:** Reduce learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Reduced learning rate to 0.001\n",
        "\n",
        "# Training loop\n",
        "epochs = 10000 # Increased epochs slightly for potential better convergence with lower LR\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(epochs):\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "# Testing\n",
        "test_data = [(1, -3), (1, 2), (1, 3), (3, 2), (-2, 1), (2, 2), (-3, 3), (3, 4), (5, 1), (2, 6)]\n",
        "\n",
        "print(\"\\nTesting the model on new cases:\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for input_data in test_data:\n",
        "        input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
        "        prediction = model(input_tensor).item()\n",
        "        expected_output = input_data[0] * input_data[1]\n",
        "        print(f'Input: {input_data}, Expected Output: {expected_output}, Predicted Output: {prediction:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq-ZWcBITCuI",
        "outputId": "b630b58a-341d-400a-833f-4ddbad041407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch [1000/10000], Loss: 0.1461\n",
            "Epoch [2000/10000], Loss: 0.0941\n",
            "Epoch [3000/10000], Loss: 0.0572\n",
            "Epoch [4000/10000], Loss: 0.0118\n",
            "Epoch [5000/10000], Loss: 0.0016\n",
            "Epoch [6000/10000], Loss: 0.0005\n",
            "Epoch [7000/10000], Loss: 0.0002\n",
            "Epoch [8000/10000], Loss: 0.0001\n",
            "Epoch [9000/10000], Loss: 0.0000\n",
            "Epoch [10000/10000], Loss: 0.0000\n",
            "Training finished.\n",
            "\n",
            "Testing the model on new cases:\n",
            "Input: (1, -3), Expected Output: -3, Predicted Output: 4.00\n",
            "Input: (1, 2), Expected Output: 2, Predicted Output: -1.01\n",
            "Input: (1, 3), Expected Output: 3, Predicted Output: -2.01\n",
            "Input: (3, 2), Expected Output: 6, Predicted Output: 1.00\n",
            "Input: (-2, 1), Expected Output: -2, Predicted Output: -3.00\n",
            "Input: (2, 2), Expected Output: 4, Predicted Output: 0.00\n",
            "Input: (-3, 3), Expected Output: -9, Predicted Output: -5.99\n",
            "Input: (3, 4), Expected Output: 12, Predicted Output: -1.00\n",
            "Input: (5, 1), Expected Output: 5, Predicted Output: 4.00\n",
            "Input: (2, 6), Expected Output: 12, Predicted Output: -4.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1:** Sketch an MLP architecture for MNIST. Input: 784 pixels (28x28); hidden: 128 neurons; output: 10 classes (0-9). Code its structure in PyTorch. Code data loading and preprocessing. Submit code and digit plots.\n",
        "\n",
        "**Task 2:** Implement the MLP class as shown for MNIST classification. Use PyTorchâ€™s nn.Module.\n",
        "\n",
        "**Task 3:** Train the MLP on MNIST for 5 epochs using the provided code.\n",
        "\n",
        "**Task 4:** Evaluate the trained MLP on MNIST test data. Compute accuracy and visualize predictions."
      ],
      "metadata": {
        "id": "rdt90WfRsRfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os # For creating data directory\n",
        "\n",
        "# --- 1. MLP Class Definition ---\n",
        "# This defines the architecture of our Multi-Layer Perceptron.\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        # Input layer: 784 neurons (for a flattened 28x28 image)\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        # First hidden layer: 128 neurons, fully connected\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        # Second hidden layer: 64 neurons, fully connected\n",
        "        self.fc3 = nn.Linear(64, 10) # Output layer: 10 neurons (for 10 digit classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the input image from (batch_size, 1, 28, 28) to (batch_size, 784)\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        # Apply the first fully connected layer followed by ReLU activation\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        # Apply the second fully connected layer followed by ReLU activation\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        # Apply the final fully connected layer.\n",
        "        # No activation here, as nn.CrossEntropyLoss implicitly handles softmax.\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# --- Configuration and Device Setup ---\n",
        "# Check if a GPU is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "model_save_path = 'mnist_mlp_model.pth' # Path to save/load the trained model\n",
        "\n",
        "# Ensure the data directory exists\n",
        "data_dir = './data'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# --- 2. Data Loading and Preprocessing ---\n",
        "# Define a transform to normalize the data to [0, 1] and convert to a PyTorch Tensor\n",
        "# transforms.ToTensor() automatically scales pixel values from [0, 255] to [0.0, 1.0]\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load the MNIST training and test datasets\n",
        "# root='./data' specifies where to store the downloaded dataset\n",
        "# train=True for the training set, train=False for the test set\n",
        "# download=True ensures that the dataset is downloaded if not already present\n",
        "# transform=transform applies the defined transformations to the loaded images\n",
        "train_dataset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "# Create DataLoaders for efficient batch processing\n",
        "# batch_size: number of samples per batch to load\n",
        "# shuffle=True for the training data to randomize the order of samples in each epoch,\n",
        "# which helps in preventing the model from getting stuck in local minima.\n",
        "# shuffle=False for the test data as order doesn't matter for evaluation.\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# --- Initial Data Validation (Optional but good practice) ---\n",
        "# Get one batch of training data to inspect its shape and content\n",
        "# iter(train_loader) creates an iterator from the DataLoader\n",
        "# next() retrieves the next item from the iterator, which is a batch of images and labels\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "print(f\"\\nInitial Data Check:\")\n",
        "print(f\"Batch shape (images): {images.shape}\") # Expected: [batch_size, 1, 28, 28]\n",
        "print(f\"Batch shape (labels): {labels.shape}\") # Expected: [batch_size]\n",
        "\n",
        "# Visualize 5 sample digits from the training batch\n",
        "fig_data_check, axes_data_check = plt.subplots(1, 5, figsize=(10, 2))\n",
        "for i in range(5):\n",
        "    # images[i] selects the i-th image from the batch\n",
        "    # .cpu() moves the tensor to CPU if it's on GPU (matplotlib works with CPU tensors/numpy arrays)\n",
        "    # .numpy() converts the PyTorch tensor to a NumPy array\n",
        "    # .squeeze() removes single-dimensional entries from the shape of an array.\n",
        "    # For MNIST images, shape is [1, 28, 28]. squeeze() makes it [28, 28] for imshow.\n",
        "    img = images[i].cpu().numpy().squeeze()\n",
        "    axes_data_check[i].imshow(img, cmap='gray')\n",
        "    axes_data_check[i].set_title(f\"Label: {labels[i].item()}\")\n",
        "    axes_data_check[i].axis('off')\n",
        "plt.suptitle('Sample MNIST Digits (Data Load Check)', y=1.05)\n",
        "plt.show()\n",
        "\n",
        "# --- 3. Model, Loss Function, and Optimizer Setup ---\n",
        "model = MLP().to(device) # Instantiate the MLP model and move it to the configured device\n",
        "print(\"\\nMLP Model Architecture:\")\n",
        "print(model)\n",
        "\n",
        "# Define the Loss Function\n",
        "# nn.CrossEntropyLoss is suitable for multi-class classification.\n",
        "# It internally applies a softmax to the model's output (logits) and then computes the negative log likelihood.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the Optimizer\n",
        "# optim.Adam is a popular adaptive learning rate optimization algorithm.\n",
        "# model.parameters() provides all the learnable parameters (weights and biases) of the model.\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# --- 4. Training Loop ---\n",
        "print(f\"\\n--- Starting Training for {num_epochs} Epochs ---\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # Set the model to training mode (enables dropout, batchnorm updates)\n",
        "    running_loss = 0.0 # To accumulate loss over batches in an epoch\n",
        "\n",
        "    # Iterate over batches of training data\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        # Move images and labels to the specified device (GPU/CPU)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 1. Forward pass: compute model's output (logits)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # 2. Calculate the loss between predicted outputs and true labels\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 3. Backward pass: compute gradients and update weights\n",
        "        optimizer.zero_grad() # Clear gradients from the previous step\n",
        "        loss.backward()       # Perform backpropagation to compute gradients of the loss w.r.t. model parameters\n",
        "\n",
        "        # 4. Update weights: Adjust model parameters using the optimizer\n",
        "        optimizer.step()      # Update model parameters using the optimizer\n",
        "\n",
        "        # Accumulate the loss for monitoring\n",
        "        running_loss += loss.item() # .item() gets the scalar value from a PyTorch tensor\n",
        "\n",
        "    # Calculate and print the average loss for the current epoch\n",
        "    # len(train_loader) gives the number of batches in the training set\n",
        "    avg_loss_epoch = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Training Loss: {avg_loss_epoch:.4f}\")\n",
        "\n",
        "# --- 5. Save the Trained Model ---\n",
        "# Save only the model's learnable parameters (state_dict), which is the recommended practice\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"\\nModel training complete. Model saved to '{model_save_path}'\")\n",
        "\n",
        "# --- 6. Load Model for Evaluation (Optional: demonstrating load functionality) ---\n",
        "# If you were to run evaluation in a separate script, you'd start from here.\n",
        "# For this combined script, the trained model is already in memory, but this shows how to load it.\n",
        "loaded_model = MLP() # Create a fresh instance of the model architecture\n",
        "try:\n",
        "    loaded_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
        "    print(f\"Model successfully loaded for evaluation from '{model_save_path}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Model file '{model_save_path}' not found for loading.\")\n",
        "    exit() # Exit if model not found for evaluation\n",
        "\n",
        "loaded_model.to(device) # Move the loaded model to the evaluation device\n",
        "loaded_model.eval() # Set the model to evaluation mode (disables dropout, fixes batchnorm stats)\n",
        "\n",
        "# --- 7. Evaluate Accuracy on Test Data ---\n",
        "print(\"\\n--- Evaluating Model on Test Data ---\")\n",
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "\n",
        "# Disable gradient calculation during inference for efficiency\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = loaded_model(images) # Get model outputs\n",
        "        # Get the predicted class (index of the highest logit)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total_samples += labels.size(0) # Accumulate total samples\n",
        "        correct_predictions += (predicted == labels).sum().item() # Count correct predictions\n",
        "\n",
        "accuracy = 100 * correct_predictions / total_samples\n",
        "print(f\"Accuracy of the MLP on the 10,000 test images: {accuracy:.2f}%\")\n",
        "\n",
        "# --- 8. Visualize Predictions on Test Data ---\n",
        "print(\"\\n--- Visualizing 10 Test Images with Predictions ---\")\n",
        "\n",
        "# Get one batch of test data for visualization\n",
        "dataiter_test = iter(test_loader)\n",
        "images_to_plot, labels_to_plot = next(dataiter_test)\n",
        "\n",
        "# Make predictions for these images using the loaded model\n",
        "images_to_plot_on_device = images_to_plot.to(device)\n",
        "with torch.no_grad():\n",
        "    outputs_to_plot = loaded_model(images_to_plot_on_device)\n",
        "    _, predicted_to_plot = torch.max(outputs_to_plot.data, 1)\n",
        "\n",
        "# Plotting setup (2 rows, 5 columns)\n",
        "fig_predictions, axes_predictions = plt.subplots(2, 5, figsize=(12, 6))\n",
        "axes_predictions = axes_predictions.flatten() # Flatten for easier iteration\n",
        "\n",
        "for i in range(10):\n",
        "    img = images_to_plot[i].cpu().numpy().squeeze() # Prepare image for matplotlib\n",
        "    true_label = labels_to_plot[i].item()\n",
        "    predicted_label = predicted_to_plot[i].item()\n",
        "\n",
        "    axes_predictions[i].imshow(img, cmap='gray')\n",
        "    # Set title color based on prediction correctness\n",
        "    color = 'green' if predicted_label == true_label else 'red'\n",
        "    axes_predictions[i].set_title(f\"P: {predicted_label}\\nA: {true_label}\", color=color, fontsize=12)\n",
        "    axes_predictions[i].axis('off') # Turn off axis labels\n",
        "\n",
        "plt.suptitle('MLP Predictions on MNIST Test Images (Green: Correct, Red: Error)', y=1.02, fontsize=14)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust layout to prevent title overlap\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFull training and evaluation pipeline complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "02gUrPhLsNTO",
        "outputId": "9967d217-b60a-441a-e805-b1be718b761a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Initial Data Check:\n",
            "Batch shape (images): torch.Size([64, 1, 28, 28])\n",
            "Batch shape (labels): torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP Model Architecture:\n",
            "MLP(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "--- Starting Training for 5 Epochs ---\n",
            "Epoch [1/5], Average Training Loss: 0.3309\n",
            "Epoch [2/5], Average Training Loss: 0.1347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# --- 1. MLP Class Definition (from previous step) ---\n",
        "# This defines the neural network architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        # Input layer: 784 neurons (28*28 flattened image)\n",
        "        # First hidden layer: 128 neurons\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        # Second hidden layer: 64 neurons\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        # Output layer: 10 neurons (for 10 classes of digits 0-9)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the input image from (batch_size, 1, 28, 28) to (batch_size, 784)\n",
        "        # The -1 tells PyTorch to automatically calculate the dimension size based on the other dimensions.\n",
        "        x = x.view(-1, 28 * 28)\n",
        "\n",
        "        # Pass through the first fully connected layer with ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Pass through the second fully connected layer with ReLU activation\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # Pass through the final fully connected layer (output layer)\n",
        "        # No activation function here; CrossEntropyLoss in PyTorch\n",
        "        # expects raw logits for multi-class classification.\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# --- 2. Data Loading and Preprocessing (from previous step) ---\n",
        "# Set device to GPU if available, else CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define a transform to normalize the data to [0, 1] and convert to a PyTorch Tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load the MNIST training and test datasets\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create DataLoaders for efficient batch processing\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# --- 3. Training Setup ---\n",
        "# Instantiate the MLP model and move it to the selected device (CPU/GPU)\n",
        "model = MLP().to(device)\n",
        "\n",
        "# Define the Loss Function\n",
        "# nn.CrossEntropyLoss is suitable for multi-class classification.\n",
        "# It internally applies a softmax to the model's output (logits) and then computes the negative log likelihood.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the Optimizer\n",
        "# optim.Adam is a popular adaptive learning rate optimization algorithm.\n",
        "# model.parameters() provides all the learnable parameters (weights and biases) of the model.\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define the number of training epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# --- 4. Training Loop ---\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    # Set the model to training mode. This is important for layers like BatchNorm or Dropout,\n",
        "    # which behave differently during training and evaluation.\n",
        "    model.train()\n",
        "    running_loss = 0.0 # To accumulate loss over batches in an epoch\n",
        "\n",
        "    # Iterate over the training data batches\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        # Move input data (images and labels) to the specified device (CPU/GPU)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 1. Forward pass: Compute model outputs\n",
        "        outputs = model(images)\n",
        "\n",
        "        # 2. Compute loss: Calculate the difference between model outputs and true labels\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 3. Backward pass: Compute gradients\n",
        "        optimizer.zero_grad() # Clear any previously computed gradients\n",
        "        loss.backward()       # Perform backpropagation to compute gradients of the loss w.r.t. model parameters\n",
        "\n",
        "        # 4. Update weights: Adjust model parameters using the optimizer\n",
        "        optimizer.step()      # Update weights based on computed gradients and learning rate\n",
        "\n",
        "        # Accumulate the loss for monitoring\n",
        "        running_loss += loss.item() # .item() gets the scalar value from a PyTorch tensor\n",
        "\n",
        "    # Calculate and print the average loss for the current epoch\n",
        "    # len(train_loader) gives the number of batches in the training set\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# --- 5. Save the trained model ---\n",
        "# Save only the model's state dictionary (learnable parameters), not the entire model instance.\n",
        "# This is generally recommended for portability.\n",
        "model_save_path = 'mnist_mlp_model.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"\\nModel saved to {model_save_path}\")\n",
        "\n",
        "# --- 6. Validation: Check if loss decreased ---\n",
        "# A simple check to ensure training stability.\n",
        "# For MNIST, after 5 epochs, the average loss should ideally be significantly below 0.5.\n",
        "if avg_loss < 0.5:\n",
        "    print(f\"Validation Check: Training stability appears good. Final average loss ({avg_loss:.4f}) is less than 0.5.\")\n",
        "else:\n",
        "    print(f\"Validation Check: Training stability might be an issue. Final average loss ({avg_loss:.4f}) is NOT less than 0.5.\")\n",
        "print(\"Training process complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARcJ3Tssh-BZ",
        "outputId": "fde7782b-91fb-424f-bcdd-6aa1a9edc6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Starting training...\n",
            "Epoch [1/5], Average Loss: 0.3386\n",
            "Epoch [2/5], Average Loss: 0.1412\n",
            "Epoch [3/5], Average Loss: 0.0956\n",
            "Epoch [4/5], Average Loss: 0.0713\n",
            "Epoch [5/5], Average Loss: 0.0548\n",
            "\n",
            "Model saved to mnist_mlp_model.pth\n",
            "Validation Check: Training stability appears good. Final average loss (0.0548) is less than 0.5.\n",
            "Training process complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. MLP Class Definition (Must be identical to the one used for training) ---\n",
        "# This class defines the architecture of our MLP. It needs to match the structure\n",
        "# of the model that was saved.\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128) # Input: 784, Output: 128\n",
        "        self.fc2 = nn.Linear(128, 64)  # Input: 128, Output: 64\n",
        "        self.fc3 = nn.Linear(64, 10)   # Input: 64, Output: 10 (for 10 classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the 28x28 image into a 784-dimensional vector\n",
        "        # The -1 tells PyTorch to automatically calculate the dimension size based on the other dimensions.\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        # Apply ReLU activation after the first two hidden layers\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        # No activation on the last layer; CrossEntropyLoss handles softmax internally\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# --- 2. Data Loading and Preprocessing (for the Test Dataset) ---\n",
        "# Determine the device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device for evaluation: {device}\")\n",
        "\n",
        "# Define the transformations for the test data: convert to Tensor and normalize to [0, 1]\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load the MNIST test dataset. We set train=False to get the test set.\n",
        "# download=True will download the dataset if it's not already present.\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create a DataLoader for the test dataset.\n",
        "# We typically don't shuffle the test set (`shuffle=False`) as the order doesn't affect evaluation.\n",
        "batch_size = 64\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# --- 3. Load the Trained Model ---\n",
        "# Instantiate a new MLP model. This new instance will have random initial weights.\n",
        "model = MLP()\n",
        "# Define the path where the trained model's state_dict was saved.\n",
        "model_save_path = 'mnist_mlp_model.pth'\n",
        "\n",
        "try:\n",
        "    # Load the saved state_dict (parameters) into the newly created model instance.\n",
        "    # map_location=device ensures the model is loaded onto the correct device (CPU/GPU).\n",
        "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
        "    print(f\"Successfully loaded trained model from '{model_save_path}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Model file '{model_save_path}' not found.\")\n",
        "    print(\"Please ensure the training script was run successfully and the model was saved.\")\n",
        "    print(\"Exiting evaluation. Train the model first to generate the '.pth' file.\")\n",
        "    exit() # Exit the script if the model file is not found\n",
        "\n",
        "# Move the model to the chosen device (GPU or CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode.\n",
        "# This disables layers like Dropout and ensures BatchNorm uses global statistics,\n",
        "# which is crucial for consistent and correct inference.\n",
        "model.eval()\n",
        "\n",
        "# --- 4. Evaluate Accuracy on Test Data ---\n",
        "print(\"\\n--- Starting Model Evaluation on Test Data ---\")\n",
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "\n",
        "# Disable gradient calculation during inference.\n",
        "# This saves memory and speeds up computations because we don't need gradients for evaluation.\n",
        "with torch.no_grad():\n",
        "    # Iterate over all batches in the test_loader\n",
        "    for images, labels in test_loader:\n",
        "        # Move the images and labels to the device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass: get model predictions (logits)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Get the predicted class. torch.max returns (max_value, argmax_index).\n",
        "        # We are interested in the index (the predicted class), so we use `_` for the max_value.\n",
        "        # The `1` indicates that we want the max along dimension 1 (the class dimension).\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update total samples count\n",
        "        total_samples += labels.size(0) # labels.size(0) is the batch_size\n",
        "\n",
        "        # Update correct predictions count\n",
        "        # (predicted == labels) creates a boolean tensor, .sum() counts True values,\n",
        "        # and .item() converts the single-element tensor to a Python number.\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the overall accuracy\n",
        "accuracy = 100 * correct_predictions / total_samples\n",
        "print(f\"Accuracy of the MLP on the {total_samples} test images: {accuracy:.2f}%\")\n",
        "\n",
        "# --- 5. Visualize Predictions ---\n",
        "print(\"\\n--- Visualizing 10 Test Images with Predictions ---\")\n",
        "\n",
        "# Get one fresh batch of test data for visualization\n",
        "dataiter = iter(test_loader)\n",
        "images_to_plot, labels_to_plot = next(dataiter)\n",
        "\n",
        "# Move these images to the device for prediction\n",
        "images_to_plot_on_device = images_to_plot.to(device)\n",
        "\n",
        "# Get predictions for these images\n",
        "with torch.no_grad(): # Ensure no gradients are computed for visualization\n",
        "    outputs_to_plot = model(images_to_plot_on_device)\n",
        "    # Get the predicted class (index with highest logit)\n",
        "    _, predicted_to_plot = torch.max(outputs_to_plot.data, 1)\n",
        "\n",
        "# Set up the plot for 10 images (2 rows, 5 columns)\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "axes = axes.flatten() # Flatten the 2x5 array of axes objects for easy indexing\n",
        "\n",
        "# Iterate through the first 10 images in the batch\n",
        "for i in range(10):\n",
        "    # Prepare the image for plotting: move to CPU, convert to NumPy, remove channel dim\n",
        "    img = images_to_plot[i].cpu().numpy().squeeze()\n",
        "    true_label = labels_to_plot[i].item() # Get the actual label as a Python number\n",
        "    predicted_label = predicted_to_plot[i].item() # Get the predicted label as a Python number\n",
        "\n",
        "    # Display the image\n",
        "    axes[i].imshow(img, cmap='gray')\n",
        "\n",
        "    # Set title with predicted (P) and actual (A) labels, color-coded for correctness\n",
        "    color = 'green' if predicted_label == true_label else 'red' # Green for correct, Red for error\n",
        "    axes[i].set_title(f\"P: {predicted_label}\\nA: {true_label}\", color=color, fontsize=12)\n",
        "    axes[i].axis('off') # Hide axes ticks and labels for cleaner image display\n",
        "\n",
        "# Add a main title for the entire figure\n",
        "plt.suptitle('MLP Predictions on MNIST Test Images (Green: Correct, Red: Error)', y=1.02, fontsize=14)\n",
        "# Adjust layout to prevent titles from overlapping\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nEvaluation and visualization complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "wnhOhq1Kjati",
        "outputId": "b5ed330c-3463-4df5-8963-bae4608e1644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device for evaluation: cpu\n",
            "Successfully loaded trained model from 'mnist_mlp_model.pth'\n",
            "\n",
            "--- Starting Model Evaluation on Test Data ---\n",
            "Accuracy of the MLP on the 10000 test images: 97.46%\n",
            "\n",
            "--- Visualizing 10 Test Images with Predictions ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation and visualization complete.\n"
          ]
        }
      ]
    }
  ]
}